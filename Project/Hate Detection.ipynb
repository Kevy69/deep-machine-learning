{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1135a423",
   "metadata": {},
   "source": [
    "todo\n",
    "1. optimize hyperparameters\n",
    "2. clean dataset\n",
    "    - balance\n",
    "3. data augmentation\n",
    "4. add requirments.txt\n",
    "5. correct title (of file as well)\n",
    "6. go through all variable names\n",
    "7. ask which types of groups should \"be in focus\". Do disabled people count?\n",
    "8. more advaned duplicate dropping?\n",
    "9. balancing the dataset needed?\n",
    "10. dedicated train test split?\n",
    "11. data augmentation only on train?\n",
    "12. remove duplicates a second time\n",
    "13. train test split after tokenization?\n",
    "14. change train test split ratio?\n",
    "15. wtf is \"output_dim\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c9a6d",
   "metadata": {},
   "source": [
    "# Hate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a1498",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8e7091f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>target_ident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I hate women.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I hate trans people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I hate gay people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I hate black people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I hate disabled people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>3897</td>\n",
       "      <td>Gay people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>3898</td>\n",
       "      <td>Black people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>3899</td>\n",
       "      <td>Disabled people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>3900</td>\n",
       "      <td>Muslims are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>3901</td>\n",
       "      <td>Immigrants are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3901 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id                                    test_case label_gold  \\\n",
       "0           1                               I hate women.     hateful   \n",
       "1           2                        I hate trans people.     hateful   \n",
       "2           3                          I hate gay people.     hateful   \n",
       "3           4                        I hate black people.     hateful   \n",
       "4           5                     I hate disabled people.     hateful   \n",
       "...       ...                                          ...        ...   \n",
       "3896     3897       Gay people are all complete 4ssholes.     hateful   \n",
       "3897     3898     Black people are all complete 4ssholes.     hateful   \n",
       "3898     3899  Disabled people are all complete 4ssholes.     hateful   \n",
       "3899     3900          Muslims are all complete 4ssholes.     hateful   \n",
       "3900     3901       Immigrants are all complete 4ssholes.     hateful   \n",
       "\n",
       "         target_ident  \n",
       "0               women  \n",
       "1        trans people  \n",
       "2          gay people  \n",
       "3        black people  \n",
       "4     disabled people  \n",
       "...               ...  \n",
       "3896       gay people  \n",
       "3897     black people  \n",
       "3898  disabled people  \n",
       "3899          Muslims  \n",
       "3900       immigrants  \n",
       "\n",
       "[3901 rows x 4 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('hate-text.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f98012",
   "metadata": {},
   "source": [
    "The dataset contains some missing values in the target_ident column, which we'll have to deal with later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4c5ef997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id         False\n",
       "test_case       False\n",
       "label_gold      False\n",
       "target_ident     True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>target_ident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1272</td>\n",
       "      <td>Fucking hell, what a day.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1273</td>\n",
       "      <td>That's a great fucking idea.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1274</td>\n",
       "      <td>No fucking way.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1275</td>\n",
       "      <td>I'm so fucking excited.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1276</td>\n",
       "      <td>Are you fucking kidding me?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>3098</td>\n",
       "      <td>Pro lifers should get the fuck out of our coun...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>3099</td>\n",
       "      <td>Most gun dealers are seriously fucked in the h...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>3100</td>\n",
       "      <td>By nature, corporate accountants are just shit...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>3101</td>\n",
       "      <td>Most real estate agents are absolute bastards.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>3102</td>\n",
       "      <td>Of course that dumbass was a snowboarder.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id                                          test_case   label_gold  \\\n",
       "1271     1272                         Fucking hell, what a day.   non-hateful   \n",
       "1272     1273                      That's a great fucking idea.   non-hateful   \n",
       "1273     1274                                   No fucking way.   non-hateful   \n",
       "1274     1275                           I'm so fucking excited.   non-hateful   \n",
       "1275     1276                        Are you fucking kidding me?  non-hateful   \n",
       "...       ...                                                ...          ...   \n",
       "3097     3098  Pro lifers should get the fuck out of our coun...  non-hateful   \n",
       "3098     3099  Most gun dealers are seriously fucked in the h...  non-hateful   \n",
       "3099     3100  By nature, corporate accountants are just shit...  non-hateful   \n",
       "3100     3101    Most real estate agents are absolute bastards.   non-hateful   \n",
       "3101     3102         Of course that dumbass was a snowboarder.   non-hateful   \n",
       "\n",
       "     target_ident  \n",
       "1271          NaN  \n",
       "1272          NaN  \n",
       "1273          NaN  \n",
       "1274          NaN  \n",
       "1275          NaN  \n",
       "...           ...  \n",
       "3097          NaN  \n",
       "3098          NaN  \n",
       "3099          NaN  \n",
       "3100          NaN  \n",
       "3101          NaN  \n",
       "\n",
       "[295 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using display() to display both at the same time. Won't comment any future use of display() (for obvious reasons)\n",
    "display(\n",
    "    data.isnull().any(),\n",
    "    data[data.isna().any(axis=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6376600",
   "metadata": {},
   "source": [
    "No duplicate texts found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d1517ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate texts: False\n"
     ]
    }
   ],
   "source": [
    "print(f'''duplicate texts: {data['test_case'].duplicated().any()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717c279",
   "metadata": {},
   "source": [
    "While the dataset is quite balanced in the target groups, it's still assymetric when it comes to the number of hate/non-hate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f284db55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_gold</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hateful</th>\n",
       "      <td>2659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-hateful</th>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "label_gold        \n",
       "hateful       2659\n",
       "non-hateful   1242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_ident</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gay people</th>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled people</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muslims</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black people</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans people</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigrants</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "target_ident          \n",
       "gay people         577\n",
       "women              535\n",
       "disabled people    510\n",
       "Muslims            510\n",
       "black people       504\n",
       "trans people       485\n",
       "immigrants         485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.DataFrame(data['label_gold'].value_counts()),\n",
    "    pd.DataFrame(data['target_ident'].value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb51211",
   "metadata": {},
   "source": [
    "No unusually short/long texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "02f8d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest: 104, \"When will it finally be clear to people that it's in a disabled person's nature to be an annoying prick?\"\n",
      "Longest: 11, \"Ihate women\"\n"
     ]
    }
   ],
   "source": [
    "longest_text_length = data['test_case'].str.len().max()\n",
    "shortest_text_length = data['test_case'].str.len().min()\n",
    "\n",
    "longest_text_index = data['test_case'].str.len().idxmax()\n",
    "shortest_text_index = data['test_case'].str.len().idxmin()\n",
    "\n",
    "print(\n",
    "    f'''Shortest: {longest_text_length}, \"{data['test_case'][longest_text_index]}\"\\n'''\n",
    "    f'''Longest: {shortest_text_length}, \"{data['test_case'][shortest_text_index]}\"'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc3645",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d2b61",
   "metadata": {},
   "source": [
    "Drop and rename columns to something more suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "95f2d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate women.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate trans people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hate gay people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hate black people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hate disabled people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text    label           target\n",
       "0            I hate women.   hateful            women\n",
       "1     I hate trans people.   hateful     trans people\n",
       "2       I hate gay people.   hateful       gay people\n",
       "3     I hate black people.   hateful     black people\n",
       "4  I hate disabled people.   hateful  disabled people"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('case_id', axis=1)\n",
    "data = data.rename(\n",
    "    columns=\n",
    "    {\n",
    "        'test_case': 'text',\n",
    "        'label_gold': 'label',\n",
    "        'target_ident': 'target',\n",
    "    }\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a93d9",
   "metadata": {},
   "source": [
    "It appears as though non of the missing target data have any relevant hate speech associated with them. This can easily be varified by manually looking at the dataset (given its tiny size). But alas, given my horrendous dyslexia i decided to programmatically varify it as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "13deda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_search_words = [\n",
    "    'gay',\n",
    "    'women',\n",
    "    'disabled',\n",
    "    'Muslims',\n",
    "    'black',\n",
    "    'trans',\n",
    "    'immigrants'\n",
    "]\n",
    "\n",
    "# Get all rows targets with NaNs\n",
    "data_target_nans = data[data['target'].isna()]\n",
    "\n",
    "for index, row in data_target_nans.iterrows():\n",
    "    for word in target_search_words:\n",
    "        # Split by words and search each one\n",
    "        if word in row['text'].split(' '):\n",
    "            print(f'''found target word in: \"{row['text']}\" row''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d7427",
   "metadata": {},
   "source": [
    "I'm now confident in dropping all rows with target NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "23295a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf744ae",
   "metadata": {},
   "source": [
    "Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "955d0920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hateful</th>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-hateful</th>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "label             \n",
       "hateful        947\n",
       "non-hateful    947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gay people</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black people</th>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muslims</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled people</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigrants</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans people</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "target                \n",
       "gay people         327\n",
       "women              306\n",
       "black people       271\n",
       "Muslims            256\n",
       "disabled people    254\n",
       "immigrants         245\n",
       "trans people       235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hateful = data['label'].value_counts()['hateful']\n",
    "non_hateful = data['label'].value_counts()['non-hateful']\n",
    "\n",
    "# Because we've got far more hateful texts\n",
    "number_of_rows_to_drop = hateful - non_hateful\n",
    "\n",
    "# randomly sample the rows and and drop them\n",
    "rows_indexes_to_remove = data[data['label'] == 'hateful'].sample(n=number_of_rows_to_drop).index\n",
    "data = data.drop(rows_indexes_to_remove)\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(data['label'].value_counts()),\n",
    "    pd.DataFrame(data['target'].value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613833d5",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606c944",
   "metadata": {},
   "source": [
    "Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a0c1182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should not allow for any immigrant to be ra...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's obvious that trans people are the very op...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any gay people on your course?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I absolutely loathe people, especially if they...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To my mind, trans lives are worth absolutely n...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>Calling trans people cockroaches is such a hor...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>People who send me messages like \"You are just...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>Gay people can be kind to you at times. Don't ...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>It's obvious that Muslims are the very opposit...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>It's in everybody's interest to just slaughter...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1894 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        label  \\\n",
       "0     We should not allow for any immigrant to be ra...  non-hateful   \n",
       "1     It's obvious that trans people are the very op...  non-hateful   \n",
       "2              Are there any gay people on your course?  non-hateful   \n",
       "3     I absolutely loathe people, especially if they...      hateful   \n",
       "4     To my mind, trans lives are worth absolutely n...      hateful   \n",
       "...                                                 ...          ...   \n",
       "1889  Calling trans people cockroaches is such a hor...  non-hateful   \n",
       "1890  People who send me messages like \"You are just...  non-hateful   \n",
       "1891  Gay people can be kind to you at times. Don't ...      hateful   \n",
       "1892  It's obvious that Muslims are the very opposit...  non-hateful   \n",
       "1893  It's in everybody's interest to just slaughter...      hateful   \n",
       "\n",
       "               target  \n",
       "0          immigrants  \n",
       "1        trans people  \n",
       "2          gay people  \n",
       "3             Muslims  \n",
       "4        trans people  \n",
       "...               ...  \n",
       "1889     trans people  \n",
       "1890  disabled people  \n",
       "1891       gay people  \n",
       "1892          Muslims  \n",
       "1893       gay people  \n",
       "\n",
       "[1894 rows x 3 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffles and returns the entire dataset as frac=1\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Reset index after having both balanced and shuffled\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1f3e12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest: 14\n",
      "Longest: 104\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'''Shortest: {data['text'].str.len().min()}\\n'''\n",
    "    f'''Longest: {data['text'].str.len().max()}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6f102123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 0: [27, 28, 18, 321, 19, 31, 57, 3, 8, 322]\n",
      "seq 1: [39, 133, 12, 16, 1, 2, 9, 189, 323, 17, 127]\n",
      "seq 2: [2, 49, 31, 14, 1, 91, 70, 163]\n",
      "seq 3: [6, 79, 434, 1, 489, 45, 41, 2, 26]\n",
      "seq 4: [3, 38, 553, 16, 33, 2, 48, 79, 40]\n"
     ]
    }
   ],
   "source": [
    "max_words_to_use = 1000\n",
    "\n",
    "# Tokenize the text data (convert them into \"sequences\")\n",
    "tokenizer = Tokenizer(num_words=max_words_to_use) # Consider only using the top 1000 words\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "tokenized_texts = tokenizer.texts_to_sequences(data['text'])\n",
    "\n",
    "# printing using loop for easier viewing (won't mention again)\n",
    "for i in range(5):\n",
    "    print(f'seq {i}: {tokenized_texts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0f45c",
   "metadata": {},
   "source": [
    "The longest series of tokenized words is only 20 items. Thus, we'll set our padding length accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "2f3412e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sequence of tokenized text: 20\n"
     ]
    }
   ],
   "source": [
    "longest_tokenized_text = max(tokenized_texts, key=len)\n",
    "print(f'longest sequence of tokenized text: {len(longest_tokenized_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "690ce80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 0: [  0   0   0   0   0   0   0   0   0   0  27  28  18 321  19  31  57   3\n",
      "   8 322]\n",
      "seq 1: [  0   0   0   0   0   0   0   0   0  39 133  12  16   1   2   9 189 323\n",
      "  17 127]\n",
      "seq 2: [  0   0   0   0   0   0   0   0   0   0   0   0   2  49  31  14   1  91\n",
      "  70 163]\n",
      "seq 3: [  0   0   0   0   0   0   0   0   0   0   0   6  79 434   1 489  45  41\n",
      "   2  26]\n",
      "seq 4: [  0   0   0   0   0   0   0   0   0   0   0   3  38 553  16  33   2  48\n",
      "  79  40]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 20\n",
    "\n",
    "# Pad the sequences to make them of uniform length\n",
    "tokenized_padded_texts = pad_sequences(tokenized_texts, maxlen=max_sequence_length)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'seq {i}: {tokenized_padded_texts[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "606d143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [1]\n",
      "targets: [0 0 0 0 1 0 0]\n",
      "\n",
      "label/target 0: 1\n",
      "label/target 1: 1\n",
      "label/target 2: 1\n",
      "label/target 3: 0\n",
      "label/target 4: 0\n",
      "label/target 5: 1\n",
      "label/target 6: 1\n",
      "label/target 7: 1\n",
      "label/target 8: 1\n",
      "label/target 9: 1\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "onehot_encoded_labels = label_binarizer.fit_transform(data['label'])\n",
    "onehot_encoded_targets = label_binarizer.fit_transform(data['target'])\n",
    "\n",
    "print(f'labels: {onehot_encoded_labels[0]}')\n",
    "print(f'targets: {onehot_encoded_targets[0]}\\n')\n",
    "\n",
    "for i in range(10):\n",
    "    # the output looks identical for both\n",
    "    print(f'label/target {i}: {onehot_encoded_labels[i][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "be632ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts shape: (1515, 20)\n",
      "train_labels shape: (1515, 1)\n",
      "train_targets shape: (1515, 7)\n",
      "test_texts shape: (379, 20)\n",
      "test_labels shape: (379, 1)\n",
      "test_targets shape: (379, 7)\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, train_labels, test_labels, train_targets, test_targets = train_test_split(\n",
    "    tokenized_padded_texts,\n",
    "    onehot_encoded_labels,\n",
    "    onehot_encoded_targets,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'train_texts shape: {np.shape(train_texts)}\\n'\n",
    "    f'train_labels shape: {np.shape(train_labels)}\\n'\n",
    "    f'train_targets shape: {np.shape(train_targets)}\\n'\n",
    "    f'test_texts shape: {np.shape(test_texts)}\\n'\n",
    "    f'test_labels shape: {np.shape(test_labels)}\\n'\n",
    "    f'test_targets shape: {np.shape(test_targets)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7640120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 6s 48ms/step - loss: 0.0000e+00 - accuracy: 0.5025 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 6s 45ms/step - loss: 1.9400 - accuracy: 0.1988 - val_loss: 1.9255 - val_accuracy: 0.2409\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.8927 - accuracy: 0.2294 - val_loss: 1.8544 - val_accuracy: 0.3927\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 1.6784 - accuracy: 0.4299 - val_loss: 1.5702 - val_accuracy: 0.4290\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.1215 - accuracy: 0.5875 - val_loss: 1.0370 - val_accuracy: 0.6634\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6813 - accuracy: 0.8177 - val_loss: 0.7280 - val_accuracy: 0.8053\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.4280 - accuracy: 0.9274 - val_loss: 0.5381 - val_accuracy: 0.8614\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.2873 - accuracy: 0.9546 - val_loss: 0.4386 - val_accuracy: 0.8779\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.1915 - accuracy: 0.9719 - val_loss: 0.3296 - val_accuracy: 0.9043\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.1483 - accuracy: 0.9851 - val_loss: 0.2634 - val_accuracy: 0.9439\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1072 - accuracy: 0.9917 - val_loss: 0.2220 - val_accuracy: 0.9406\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0831 - accuracy: 0.9959 - val_loss: 0.2195 - val_accuracy: 0.9439\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0680 - accuracy: 0.9975 - val_loss: 0.2132 - val_accuracy: 0.9439\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0554 - accuracy: 0.9975 - val_loss: 0.2216 - val_accuracy: 0.9274\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9373\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0446 - accuracy: 0.9992 - val_loss: 0.1812 - val_accuracy: 0.9406\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9340\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9406\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9406\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0224 - accuracy: 0.9992 - val_loss: 0.1454 - val_accuracy: 0.9571\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9505\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0174 - accuracy: 0.9992 - val_loss: 0.1496 - val_accuracy: 0.9472\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9571\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9538\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9571\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9571\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9604\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9571\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9505\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9571\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9571\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9571\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9571\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9637\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9637\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9637\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9637\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9637\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9637\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9670\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9637\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9670\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9670\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9637\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9703\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9703\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9637\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9736\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9637\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9670\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9703\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9736\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9670\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9736\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9736\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9736\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9670\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9703\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9670\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9736\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9670\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9670\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 9.8220e-04 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9736\n"
     ]
    }
   ],
   "source": [
    "# models = {}\n",
    "# model_names_datasets = {'label_model': train_labels, 'target_model': train_targets}\n",
    "\n",
    "# for model_name, labels in model_names_datasets.items():\n",
    "#     model = Sequential([\n",
    "#         Embedding(\n",
    "#             input_dim=max_words_to_use,\n",
    "#             input_length=max_sequence_length,\n",
    "#             output_dim=32\n",
    "#         ),\n",
    "#         LSTM(units=32, activation='tanh'),\n",
    "        \n",
    "#         # The number of neurons at the output depend on the number of classes we have\n",
    "#         # We get the number of classes by taking the shape of the label arrays as they're one-hot encoded\n",
    "#         Dense(labels.shape[1], activation='sigmoid')\n",
    "#     ])\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Using a patience and start_from_epoch of 10 as the model is still all over the place before that\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "\n",
    "#     # Will update the model objects inside the dictionary\n",
    "#     history = model.fit(train_texts, labels, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "#     models[model_name] = model\n",
    "#     models[model_name + '_history'] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3b466938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 41ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0000e+00 - accuracy: 0.5033 - val_loss: 0.0000e+00 - val_accuracy: 0.5083\n",
      "Epoch 5/100\n",
      " 5/38 [==>...........................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[402], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, start_from_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Will update the model objects inside the dictionary\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=max_words_to_use,\n",
    "        input_length=max_sequence_length,\n",
    "        output_dim=32\n",
    "    ),\n",
    "    LSTM(units=32, activation='tanh'),\n",
    "    \n",
    "    # The number of neurons at the output depend on the number of classes we have\n",
    "    # We get the number of classes by taking the shape of the label arrays as they're one-hot encoded\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Using a patience and start_from_epoch of 10 as the model is still all over the place before that\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "\n",
    "# Will update the model objects inside the dictionary\n",
    "history = model.fit(train_texts, train_labels, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "d3cee8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_model': <keras.engine.sequential.Sequential at 0x18162dd3cd0>,\n",
       " 'label_model_history': <keras.callbacks.History at 0x18162e04760>,\n",
       " 'target_model': <keras.engine.sequential.Sequential at 0x1816672edf0>,\n",
       " 'target_model_history': <keras.callbacks.History at 0x181667d4c10>}"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "02fdacb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.0%\n",
      "Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_model = models['label_model']\n",
    "history = models['label_model_history']\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = test_model.evaluate(test_texts, test_labels, verbose=0)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for subplot, metric in enumerate(['accuracy', 'loss'], 1):\n",
    "    plt.subplot(1, 2, subplot)\n",
    "    plt.plot(history.history[metric], label='Training Accuracy')\n",
    "    plt.plot(history.history[f'val_{metric}'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f'Accuracy: {round(test_accuracy, 2) * 100}%\\n'\n",
    "    f'Loss: {round(test_loss, 2)}'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "626645a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[401], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8448b",
   "metadata": {},
   "source": [
    "# JUNK BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f432cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model), history in zip(models.items(), histories):\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    for subplot, metric in enumerate(['accuracy', 'loss'], 1):\n",
    "        plt.subplot(1, 2, subplot)\n",
    "        plt.plot(history.history[metric], label='Training Accuracy')\n",
    "        plt.plot(history.history[f'val_{metric}'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.suptitle(f'Sentiment analysis using an {name}')\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        f'Accuracy: {round(test_accuracy, 2) * 100}%\\n'\n",
    "        f'Loss: {round(test_loss, 2)}'    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92412252",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model), history in zip(models.items(), histories):\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    for subplot, metric in enumerate(['accuracy', 'loss'], 1):\n",
    "        plt.subplot(1, 2, subplot)\n",
    "        plt.plot(history.history[metric], label='Training Accuracy')\n",
    "        plt.plot(history.history[f'val_{metric}'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.suptitle(f'Sentiment analysis using an {name}')\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        f'Accuracy: {round(test_accuracy, 2) * 100}%\\n'\n",
    "        f'Loss: {round(test_loss, 2)}'    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f125b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_model': <keras.engine.sequential.Sequential at 0x18155942040>,\n",
       " 'label_model_history': <keras.callbacks.History at 0x1815d0bfb80>,\n",
       " 'target_model': <keras.engine.sequential.Sequential at 0x18155b4d490>,\n",
       " 'target_model_history': <keras.callbacks.History at 0x1815d0f4d60>}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty straightforward code once you read it twice\n",
    "for (name, model), history in zip(models.items(), histories):\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    predictions = model.predict(x_test, verbose=0)\n",
    "    \n",
    "    # Argmax the predictions/labels in order to convert them into class labels\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    actual_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    f1 = f1_score(actual_classes, predicted_classes, average='weighted')\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(actual_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    for subplot, metric in enumerate(['accuracy', 'loss'], 1):\n",
    "        plt.subplot(1, 2, subplot)\n",
    "        plt.plot(history.history[metric], label='Training Accuracy')\n",
    "        plt.plot(history.history[f'val_{metric}'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.suptitle(f'Sentiment analysis using an {name} on train/val data')\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        f'Test accuracy: {round(test_accuracy, 2) * 100}%\\n'\n",
    "        f'Test loss: {round(test_loss, 2)}\\n'\n",
    "        f'Test F1: {f1}'\n",
    "    )\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues', \n",
    "        xticklabels=np.unique(actual_classes),\n",
    "        yticklabels=np.unique(actual_classes)\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Test data confusion matrix')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
