{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1135a423",
   "metadata": {},
   "source": [
    "todo\n",
    "1. optimize hyperparameters\n",
    "2. clean dataset\n",
    "    - balance\n",
    "3. data augmentation\n",
    "4. add requirments.txt\n",
    "5. correct title (of file as well)\n",
    "6. go through all variable names\n",
    "7. ask which types of groups should \"be in focus\". Do disabled people count?\n",
    "8. more advaned duplicate dropping?\n",
    "9. balancing the dataset needed?\n",
    "10. dedicated train test split?\n",
    "11. data augmentation only on train?\n",
    "12. remove duplicates a second time\n",
    "13. train test split after tokenization?\n",
    "14. change train test split ratio?\n",
    "15. wtf is \"output_dim\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c9a6d",
   "metadata": {},
   "source": [
    "# Hate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a1498",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8e7091f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>target_ident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I hate women.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I hate trans people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I hate gay people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I hate black people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I hate disabled people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>3897</td>\n",
       "      <td>Gay people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>3898</td>\n",
       "      <td>Black people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>3899</td>\n",
       "      <td>Disabled people are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>3900</td>\n",
       "      <td>Muslims are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>3901</td>\n",
       "      <td>Immigrants are all complete 4ssholes.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3901 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id                                    test_case label_gold  \\\n",
       "0           1                               I hate women.     hateful   \n",
       "1           2                        I hate trans people.     hateful   \n",
       "2           3                          I hate gay people.     hateful   \n",
       "3           4                        I hate black people.     hateful   \n",
       "4           5                     I hate disabled people.     hateful   \n",
       "...       ...                                          ...        ...   \n",
       "3896     3897       Gay people are all complete 4ssholes.     hateful   \n",
       "3897     3898     Black people are all complete 4ssholes.     hateful   \n",
       "3898     3899  Disabled people are all complete 4ssholes.     hateful   \n",
       "3899     3900          Muslims are all complete 4ssholes.     hateful   \n",
       "3900     3901       Immigrants are all complete 4ssholes.     hateful   \n",
       "\n",
       "         target_ident  \n",
       "0               women  \n",
       "1        trans people  \n",
       "2          gay people  \n",
       "3        black people  \n",
       "4     disabled people  \n",
       "...               ...  \n",
       "3896       gay people  \n",
       "3897     black people  \n",
       "3898  disabled people  \n",
       "3899          Muslims  \n",
       "3900       immigrants  \n",
       "\n",
       "[3901 rows x 4 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('hate-text.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f98012",
   "metadata": {},
   "source": [
    "The dataset contains some missing values in the target_ident column, which we'll have to deal with later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4c5ef997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id         False\n",
       "test_case       False\n",
       "label_gold      False\n",
       "target_ident     True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>target_ident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1272</td>\n",
       "      <td>Fucking hell, what a day.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1273</td>\n",
       "      <td>That's a great fucking idea.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1274</td>\n",
       "      <td>No fucking way.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1275</td>\n",
       "      <td>I'm so fucking excited.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1276</td>\n",
       "      <td>Are you fucking kidding me?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>3098</td>\n",
       "      <td>Pro lifers should get the fuck out of our coun...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>3099</td>\n",
       "      <td>Most gun dealers are seriously fucked in the h...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>3100</td>\n",
       "      <td>By nature, corporate accountants are just shit...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>3101</td>\n",
       "      <td>Most real estate agents are absolute bastards.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>3102</td>\n",
       "      <td>Of course that dumbass was a snowboarder.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id                                          test_case   label_gold  \\\n",
       "1271     1272                         Fucking hell, what a day.   non-hateful   \n",
       "1272     1273                      That's a great fucking idea.   non-hateful   \n",
       "1273     1274                                   No fucking way.   non-hateful   \n",
       "1274     1275                           I'm so fucking excited.   non-hateful   \n",
       "1275     1276                        Are you fucking kidding me?  non-hateful   \n",
       "...       ...                                                ...          ...   \n",
       "3097     3098  Pro lifers should get the fuck out of our coun...  non-hateful   \n",
       "3098     3099  Most gun dealers are seriously fucked in the h...  non-hateful   \n",
       "3099     3100  By nature, corporate accountants are just shit...  non-hateful   \n",
       "3100     3101    Most real estate agents are absolute bastards.   non-hateful   \n",
       "3101     3102         Of course that dumbass was a snowboarder.   non-hateful   \n",
       "\n",
       "     target_ident  \n",
       "1271          NaN  \n",
       "1272          NaN  \n",
       "1273          NaN  \n",
       "1274          NaN  \n",
       "1275          NaN  \n",
       "...           ...  \n",
       "3097          NaN  \n",
       "3098          NaN  \n",
       "3099          NaN  \n",
       "3100          NaN  \n",
       "3101          NaN  \n",
       "\n",
       "[295 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using display() to display both at the same time. Won't comment any future use of display() (for obvious reasons)\n",
    "display(\n",
    "    data.isnull().any(),\n",
    "    data[data.isna().any(axis=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6376600",
   "metadata": {},
   "source": [
    "No duplicate texts found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d1517ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate texts: False\n"
     ]
    }
   ],
   "source": [
    "print(f'''duplicate texts: {data['test_case'].duplicated().any()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717c279",
   "metadata": {},
   "source": [
    "While the dataset is quite balanced in the target groups, it's still assymetric when it comes to the number of hate/non-hate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f284db55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_gold</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hateful</th>\n",
       "      <td>2659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-hateful</th>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "label_gold        \n",
       "hateful       2659\n",
       "non-hateful   1242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_ident</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gay people</th>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled people</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muslims</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black people</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans people</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigrants</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "target_ident          \n",
       "gay people         577\n",
       "women              535\n",
       "disabled people    510\n",
       "Muslims            510\n",
       "black people       504\n",
       "trans people       485\n",
       "immigrants         485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.DataFrame(data['label_gold'].value_counts()),\n",
    "    pd.DataFrame(data['target_ident'].value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb51211",
   "metadata": {},
   "source": [
    "No unusually short/long texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "02f8d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest: 104, \"When will it finally be clear to people that it's in a disabled person's nature to be an annoying prick?\"\n",
      "Longest: 11, \"Ihate women\"\n"
     ]
    }
   ],
   "source": [
    "longest_text_length = data['test_case'].str.len().max()\n",
    "shortest_text_length = data['test_case'].str.len().min()\n",
    "\n",
    "longest_text_index = data['test_case'].str.len().idxmax()\n",
    "shortest_text_index = data['test_case'].str.len().idxmin()\n",
    "\n",
    "print(\n",
    "    f'''Shortest: {longest_text_length}, \"{data['test_case'][longest_text_index]}\"\\n'''\n",
    "    f'''Longest: {shortest_text_length}, \"{data['test_case'][shortest_text_index]}\"'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc3645",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d2b61",
   "metadata": {},
   "source": [
    "Drop and rename columns to something more suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "95f2d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate women.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate trans people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>trans people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hate gay people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hate black people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hate disabled people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>disabled people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text    label           target\n",
       "0            I hate women.   hateful            women\n",
       "1     I hate trans people.   hateful     trans people\n",
       "2       I hate gay people.   hateful       gay people\n",
       "3     I hate black people.   hateful     black people\n",
       "4  I hate disabled people.   hateful  disabled people"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('case_id', axis=1)\n",
    "data = data.rename(\n",
    "    columns=\n",
    "    {\n",
    "        'test_case': 'text',\n",
    "        'label_gold': 'label',\n",
    "        'target_ident': 'target',\n",
    "    }\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a93d9",
   "metadata": {},
   "source": [
    "It appears as though non of the missing target data have any relevant hate speech associated with them. This can easily be varified by manually looking at the dataset (given its tiny size). But alas, given my horrendous dyslexia i decided to programmatically varify it as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "13deda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_search_words = [\n",
    "    'gay',\n",
    "    'women',\n",
    "    'disabled',\n",
    "    'Muslims',\n",
    "    'black',\n",
    "    'trans',\n",
    "    'immigrants'\n",
    "]\n",
    "\n",
    "# Get all rows targets with NaNs\n",
    "data_target_nans = data[data['target'].isna()]\n",
    "\n",
    "for index, row in data_target_nans.iterrows():\n",
    "    for word in target_search_words:\n",
    "        # Split by words and search each one\n",
    "        if word in row['text'].split(' '):\n",
    "            print(f'''found target word in: \"{row['text']}\" row''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d7427",
   "metadata": {},
   "source": [
    "I'm now confident in dropping all rows with target NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "23295a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf744ae",
   "metadata": {},
   "source": [
    "Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "955d0920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hateful</th>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-hateful</th>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "label             \n",
       "hateful        947\n",
       "non-hateful    947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gay people</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muslims</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black people</th>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled people</th>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigrants</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans people</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "target                \n",
       "gay people         317\n",
       "women              292\n",
       "Muslims            266\n",
       "black people       265\n",
       "disabled people    261\n",
       "immigrants         248\n",
       "trans people       245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hateful = data['label'].value_counts()['hateful']\n",
    "non_hateful = data['label'].value_counts()['non-hateful']\n",
    "\n",
    "# Because we've got far more hateful texts\n",
    "number_of_rows_to_drop = hateful - non_hateful\n",
    "\n",
    "# randomly sample the rows and and drop them\n",
    "rows_indexes_to_remove = data[data['label'] == 'hateful'].sample(n=number_of_rows_to_drop).index\n",
    "data = data.drop(rows_indexes_to_remove)\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(data['label'].value_counts()),\n",
    "    pd.DataFrame(data['target'].value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613833d5",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606c944",
   "metadata": {},
   "source": [
    "Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a0c1182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The world would be better off without Muslims ...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She should be kicked off the platform for sayi...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Typical of an immigrant to be that stup1d.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She's got a fag in her mouth, and she's squint...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>gay people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immigrants are parasites to our society.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>There is a woman on my football team.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>Immigrants are human garbage.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>immigrants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>If you say \"I hate women\", then you are a bigot!</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>Women being in charge is a danger to our count...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>We would be better off if those Muslims were e...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>Muslims</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1894 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        label  \\\n",
       "0     The world would be better off without Muslims ...      hateful   \n",
       "1     She should be kicked off the platform for sayi...  non-hateful   \n",
       "2           Typical of an immigrant to be that stup1d.       hateful   \n",
       "3     She's got a fag in her mouth, and she's squint...  non-hateful   \n",
       "4             Immigrants are parasites to our society.       hateful   \n",
       "...                                                 ...          ...   \n",
       "1889             There is a woman on my football team.   non-hateful   \n",
       "1890                     Immigrants are human garbage.       hateful   \n",
       "1891   If you say \"I hate women\", then you are a bigot!  non-hateful   \n",
       "1892  Women being in charge is a danger to our count...      hateful   \n",
       "1893  We would be better off if those Muslims were e...      hateful   \n",
       "\n",
       "          target  \n",
       "0        Muslims  \n",
       "1     immigrants  \n",
       "2     immigrants  \n",
       "3     gay people  \n",
       "4     immigrants  \n",
       "...          ...  \n",
       "1889       women  \n",
       "1890  immigrants  \n",
       "1891       women  \n",
       "1892       women  \n",
       "1893     Muslims  \n",
       "\n",
       "[1894 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffles and returns the entire dataset as frac=1\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Reset index after having both balanced and shuffled\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1f3e12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest: 14\n",
      "Longest: 101\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'''Shortest: {data['text'].str.len().min()}\\n'''\n",
    "    f'''Longest: {data['text'].str.len().max()}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6f102123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 0: [10, 137, 40, 9, 223, 104, 143, 23, 7, 4]\n",
      "seq 1: [224, 27, 9, 306, 104, 10, 307, 20, 61, 24, 27, 8, 9, 182]\n",
      "seq 2: [50, 19, 92, 62, 3, 9, 11, 499]\n",
      "seq 3: [559, 560, 5, 160, 12, 265, 728, 35, 559, 729, 265, 730, 424, 10, 731]\n",
      "seq 4: [24, 2, 308, 3, 74, 75]\n"
     ]
    }
   ],
   "source": [
    "max_words_to_use = 1000\n",
    "\n",
    "# Tokenize the text data (convert them into \"sequences\")\n",
    "tokenizer = Tokenizer(num_words=max_words_to_use) # Consider only using the top 1000 words\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "tokenized_texts = tokenizer.texts_to_sequences(data['text'])\n",
    "\n",
    "# printing using loop for easier viewing (won't mention again)\n",
    "for i in range(5):\n",
    "    print(f'seq {i}: {tokenized_texts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0f45c",
   "metadata": {},
   "source": [
    "The longest series of tokenized words is only 20 items. Thus, we'll set our padding length accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2f3412e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sequence of tokenized text: 20\n"
     ]
    }
   ],
   "source": [
    "longest_tokenized_text = max(tokenized_texts, key=len)\n",
    "print(f'longest sequence of tokenized text: {len(longest_tokenized_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "690ce80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq 0: [  0   0   0   0   0   0   0   0   0   0  10 137  40   9 223 104 143  23\n",
      "   7   4]\n",
      "seq 1: [  0   0   0   0   0   0 224  27   9 306 104  10 307  20  61  24  27   8\n",
      "   9 182]\n",
      "seq 2: [  0   0   0   0   0   0   0   0   0   0   0   0  50  19  92  62   3   9\n",
      "  11 499]\n",
      "seq 3: [  0   0   0   0   0 559 560   5 160  12 265 728  35 559 729 265 730 424\n",
      "  10 731]\n",
      "seq 4: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  24   2 308   3\n",
      "  74  75]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 20\n",
    "\n",
    "# Pad the sequences to make them of uniform length\n",
    "tokenized_padded_texts = pad_sequences(tokenized_texts, maxlen=max_sequence_length)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'seq {i}: {tokenized_padded_texts[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "606d143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [0]\n",
      "targets: [1 0 0 0 0 0 0]\n",
      "\n",
      "label/target 0: 0\n",
      "label/target 1: 1\n",
      "label/target 2: 0\n",
      "label/target 3: 1\n",
      "label/target 4: 0\n",
      "label/target 5: 1\n",
      "label/target 6: 1\n",
      "label/target 7: 1\n",
      "label/target 8: 0\n",
      "label/target 9: 0\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "onehot_encoded_labels = label_binarizer.fit_transform(data['label'])\n",
    "onehot_encoded_targets = label_binarizer.fit_transform(data['target'])\n",
    "\n",
    "print(f'labels: {onehot_encoded_labels[0]}')\n",
    "print(f'targets: {onehot_encoded_targets[0]}\\n')\n",
    "\n",
    "for i in range(10):\n",
    "    # the output looks identical for both\n",
    "    print(f'label/target {i}: {onehot_encoded_labels[i][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "be632ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts shape: (1515, 20)\n",
      "train_labels shape: (1515, 1)\n",
      "train_targets shape: (1515, 7)\n",
      "test_texts shape: (379, 20)\n",
      "test_labels shape: (379, 1)\n",
      "test_targets shape: (379, 7)\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, train_labels, test_labels, train_targets, test_targets = train_test_split(\n",
    "    tokenized_padded_texts,\n",
    "    onehot_encoded_labels,\n",
    "    onehot_encoded_targets,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'train_texts shape: {np.shape(train_texts)}\\n'\n",
    "    f'train_labels shape: {np.shape(train_labels)}\\n'\n",
    "    f'train_targets shape: {np.shape(train_targets)}\\n'\n",
    "    f'test_texts shape: {np.shape(test_texts)}\\n'\n",
    "    f'test_labels shape: {np.shape(test_labels)}\\n'\n",
    "    f'test_targets shape: {np.shape(test_targets)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7640120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in [train_labels]\n",
    "model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=max_words_to_use,\n",
    "        input_length=max_sequence_length,\n",
    "        output_dim=32\n",
    "    ),\n",
    "    LSTM(units=32, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Using a patience and start_from_epoch of 10 as the model is still all over the place before that\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "\n",
    "# Will update the model objects inside the dictionary\n",
    "history = model.fit(train_texts, train_labels, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "92daac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 7s 42ms/step - loss: 0.0000e+00 - accuracy: 0.4827 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4851 - val_loss: 0.0000e+00 - val_accuracy: 0.5314\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
