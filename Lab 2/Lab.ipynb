{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b09d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: balance dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb5209",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9891682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "341d4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'sadness' 'joy' 'love' 'fear' 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel so pissed off over an old friend and so...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive found it has made a huge difference especi...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i also feel it is unfortunate that nearly all ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel petty a href http clairee</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i used to believe that a feeling like fear was...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>i was i might be buying stuff from there but i...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i like sonam deepika and genelia who i feel ar...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>i feel pathetic that i can hardly go a whole d...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>id have spent more time with her on reading i ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>i do however feel like one of those pathetic g...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "0      i feel so pissed off over an old friend and so...    anger\n",
       "1      ive found it has made a huge difference especi...    anger\n",
       "2      i also feel it is unfortunate that nearly all ...  sadness\n",
       "3                       i feel petty a href http clairee    anger\n",
       "4      i used to believe that a feeling like fear was...  sadness\n",
       "...                                                  ...      ...\n",
       "19995  i was i might be buying stuff from there but i...      joy\n",
       "19996  i like sonam deepika and genelia who i feel ar...      joy\n",
       "19997  i feel pathetic that i can hardly go a whole d...  sadness\n",
       "19998  id have spent more time with her on reading i ...  sadness\n",
       "19999  i do however feel like one of those pathetic g...  sadness\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('emotions.csv')\n",
    "\n",
    "display(\n",
    "    data,\n",
    "    print(data['label'].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "32ddbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest \"review\" characters/word count: 300/62\n"
     ]
    }
   ],
   "source": [
    "# Find the longest \"review\" (for lack of a better word) and count the number of chars/words. Useful in order\n",
    "# to set an appropriate max_words for pad_sequences.\n",
    "longest_row_index = data['text'].str.len().idxmax()\n",
    "longest_row = data['text'].loc[longest_row_index]\n",
    "\n",
    "longest_review_char_count = len(longest_row)\n",
    "longest_review_word_count = len(longest_row.split(' '))\n",
    "\n",
    "print(f'Longest \"review\" characters/word count: {longest_review_char_count}/{longest_review_word_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "090bd1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 14, 513, 161, 115, 76, 274, 277, 3, 68, 178]\n",
      "[73, 322, 12, 99, 131, 6, 275, 29, 5, 24, 10, 3, 5, 10, 714, 119, 14, 84, 3, 152, 495]\n",
      "[1, 116, 2, 12, 21, 762, 8, 35, 5, 964, 9, 87, 4, 782, 5, 367, 57, 27, 50]\n",
      "[1, 2, 665, 6, 203, 187]\n",
      "[1, 323, 4, 300, 8, 6, 7, 13, 763, 18, 4, 27, 614, 34, 111, 162, 37, 29, 22, 11, 6, 242]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data \n",
    "tokenizer = Tokenizer(num_words=1000) # Consider only using the top 1000 words, as those \n",
    "\n",
    "# \"Learn\" our dataset\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "\n",
    "# printing using a loop for easier viewing\n",
    "for i in range(5):\n",
    "    print(sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to make them of uniform length\n",
    "maxlen = 100  # Set the maximum length of sequences\n",
    "data_pad = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create label encoding for the emotions\n",
    "labels = pd.get_dummies(data['label'])\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_pad, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32, input_length=maxlen))  # Embedding layer\n",
    "model.add(SimpleRNN(32))  # Simple RNN layer\n",
    "model.add(Dense(4, activation='softmax'))  # Dense layer with softmax activation for multi-label classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
